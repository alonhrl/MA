{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code receives an input directory with Eumetsat NetCDF files and longitude and latitude baoundaries.\n",
    "It creates a CSV file with the following columns:\n",
    "longitude | latitude | date | daily-radiation\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "minlat = 29.5\n",
    "maxlat = 33.25\n",
    "minlon = 34.38\n",
    "maxlon = 35.8\n",
    "count = 0\n",
    "\n",
    "def get_file_hour_month_year(fileName):\n",
    "    #extract last part in the file name which is the date\n",
    "    filename = os.path.basename(fileName)\n",
    "    tempTuple = os.path.splitext(filename)\n",
    "    filename = tempTuple[0]\n",
    "    fileNameArr = np.array(filename.split(\"-\"))\n",
    "    filedate = fileNameArr[len(fileNameArr)-1]\n",
    "    \n",
    "    #the format is 222001010900Z YYYYMMDDHHMM\n",
    "    year = int(filedate[:4])\n",
    "    month = int(filedate[4:6])\n",
    "    day = int(filedate[6:8])\n",
    "    hour = int(filedate[8:10])\n",
    "    minute = int(filedate[10:12])\n",
    "    \n",
    "    return (year, month, day, hour)\n",
    "\n",
    "def find_start_lat_lon_and_interval(filename):\n",
    "    \n",
    "    nc_file = Dataset(filename)\n",
    "    \n",
    "    lat_var = nc_file.variables['lat']\n",
    "    lats_size = len(lat_var)\n",
    "    lat_start = lat_var[0] if (lat_var[0] < lat_var[lats_size-1]) else lat_var[lats_size-1]\n",
    "    \n",
    "    lon_var = nc_file.variables['lon']\n",
    "    lons_size = len(lon_var)\n",
    "    lon_start = lon_var[0] if (lon_var[0] < lon_var[lons_size-1]) else lon_var[lons_size-1]\n",
    "    \n",
    "    # we assume lats % lons have the same interval \n",
    "    interval = (abs(lat_var[0]) + abs(lat_var[lats_size-1]))/lats_size\n",
    "                \n",
    "    return(lon_start, lat_start , round(interval, 2))\n",
    "\n",
    "def calc_first_and_last_indices_for_range(filename, minlon, maxlon, minlat, maxlat):\n",
    "    \n",
    "    #find start lats & lons\n",
    "    lon_start, lat_start , interval = find_start_lat_lon_and_interval(filename)\n",
    "    \n",
    "    #print(\"lon_start %d, lat_start %d, interval %f\" %(lon_start, lat_start , interval))\n",
    "    #print(\"minlon %f, maxlon %f, minlat %f, maxlat %f\" %(minlon, maxlon, minlat, maxlat))\n",
    "    latOffsetStart =  (minlat+abs(lat_start))/interval\n",
    "    latOffsetEnd =  (maxlat+abs(lat_start))/interval\n",
    "    lonOffsetStart =  (minlon+abs(lon_start))/interval\n",
    "    lonOffsetEnd =  (maxlon+abs(lon_start))/interval\n",
    "    \n",
    "    #get the coordinates values from the file\n",
    "    nc_file = Dataset(filename)  \n",
    "    lat_var = nc_file.variables['lat']\n",
    "    lon_var = nc_file.variables['lon']\n",
    "    \n",
    "    #find the cells which are closest to the start & end coordinates for lat and lon\n",
    "    latStartOffset = latOffsetStart if (((minlat - lat_var[latOffsetStart])) < (lat_var[latOffsetStart+1] - minlat)) else latOffsetStart\n",
    "    latEndOffset = latOffsetEnd if (((maxlat - lat_var[latOffsetEnd])) < (lat_var[latOffsetEnd+1] - maxlat)) else latOffsetEnd\n",
    "    lonStartOffset = lonOffsetStart if (((minlon - lon_var[lonOffsetStart])) < (lon_var[lonOffsetStart+1] - minlon)) else lonOffsetStart\n",
    "    lonEndOffset = lonOffsetEnd if (((maxlon - lon_var[lonOffsetEnd])) < (lon_var[lonOffsetEnd+1] - maxlon)) else lonOffsetEnd\n",
    "    \n",
    "    return(round(lonStartOffset), round(lonEndOffset), round(latStartOffset), round(latEndOffset))\n",
    "\n",
    "inputDir = '/Users/alonhrl/Downloads/Archive'\n",
    "output_csv_file = os.path.join(inputDir, 'daily_eumetsat_rad.csv')\n",
    "\n",
    "#we assume same array size for all files thus we choose some file to make the calc and get the fixed data\n",
    "fileName = file_path = os.path.join(inputDir, 'S-OSI_-FRA_-MSG_-DLISSIH_____-202201010000Z.nc')\n",
    "minLon, maxLon, minLat, maxLat = calc_first_and_last_indices_for_range(fileName, minlon, maxlon, minlat, maxlat)\n",
    "lon_start, lat_start , interval = find_start_lat_lon_and_interval(fileName)\n",
    "# Initialize lon_lat_date_arr as a list of lists with None values\n",
    "lon_lat_date_arr = [[{} for _ in range(maxLat - minLat + 1)] for _ in range(maxLon - minLon + 1)]\n",
    "\n",
    "\n",
    "\n",
    "# iterate recursively over all netCDF files in the directory\n",
    "for filename in glob.iglob(inputDir + '**/**', recursive=True):\n",
    "    file_name, file_extension = os.path.splitext(filename)\n",
    "    if file_extension == '.nc':\n",
    "        count += 1\n",
    "        \n",
    "        fh = Dataset(filename, mode='r')\n",
    "        ssi = fh.variables['ssi']\n",
    "\n",
    "        # iterate over all indices\n",
    "        for lonIndex in range(minLon, maxLon + 1):\n",
    "            for latIndex in range(minLat, maxLat + 1):\n",
    "                # print(\"time: %s, lonIndx: %d, latIndx: %d,  ssi: %.2f\" %(get_file_date(filename), cLon, cLat, ssi[cLon,cLat]))\n",
    "                year, month, day, hour = get_file_hour_month_year(filename)\n",
    "                date = f\"{day:02d}-{month:02d}-{year:02d}\"\n",
    "                # if specific date is not in the list -> add it\n",
    "                #need to subtract the min index values as our array starts from 0\n",
    "                if not date in lon_lat_date_arr[lonIndex-minLon][latIndex-minLat].keys():\n",
    "                    lon_lat_date_arr[lonIndex-minLon][latIndex-minLat][date] = 0\n",
    "                               \n",
    "                ssiVal = ssi[latIndex, lonIndex]\n",
    "                # if value is 'nan' set to 0\n",
    "                if type(ssiVal) is not np.float64:\n",
    "                    #not a valid value, continue\n",
    "                    continue\n",
    "                else:\n",
    "                    lon_lat_date_arr[lonIndex-minLon][latIndex-minLat][date] += int(ssiVal)\n",
    "\n",
    "print (\"Processed %d files!\" % (count))\n",
    "\n",
    "# create a CSV file with the following columns:\n",
    "# longitude | latitude | date | total radiation\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    # Define the CSV writer\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['lon', 'lat', 'date', 'daily radiation'])\n",
    "    \n",
    "    # Iterate over the 2D array and write each entry to the CSV file\n",
    "    for lon, lat_data in enumerate(lon_lat_date_arr):\n",
    "        for lat, date_radiation in enumerate(lat_data):\n",
    "            for date, radiation in date_radiation.items():\n",
    "                #convert back from indices to longitude and latitude\n",
    "                realLon = lon_start + (lon+minLon)*interval\n",
    "                realLat = lat_start + (lat+minLat)*interval\n",
    "                # Write the data to the CSV file\n",
    "                csv_writer.writerow([realLon, realLat, date, radiation])\n",
    "\n",
    "print(\"%s created successfully!\" % output_csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eumetsat",
   "language": "python",
   "name": "eumetsat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
